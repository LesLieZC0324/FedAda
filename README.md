# FedAda

Client-edge-cloud Federated Learning (CEC-FL) is emerging as an increasingly popular FL paradigm, alleviating the performance limitations of conventional cloud-centric Federated Learning (FL) by incorporating edge computing. 
Improving model quality and training efficiency is an important research topic in CEC-FL. 
Aggregation frequency control has received widespread attention due to its superiority among optimisation methods. However, existing solutions still suffer from unsatisfactory training performance in heterogeneous and dynamic environments. 
This paper proposes FedAda, a communication-efficient CEC-FL training method that enhances training performance through adaptive aggregation frequency adjustment. 
We theoretically analyze the relationship between model convergence and aggregation frequency. On this basis, we propose an approximation algorithm to calculate aggregation frequency aligned with heterogeneous and dynamic node capabilities, achieving superior convergence accuracy and speed. 
Simulation results validate the effectiveness and efficiency of FedAda, demonstrating up to 4% improvement in model accuracy, 6.8X shorter training time, and 3.3X less communication overhead compared to prior solutions.
